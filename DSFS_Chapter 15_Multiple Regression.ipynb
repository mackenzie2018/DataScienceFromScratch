{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.869769Z",
     "start_time": "2020-03-21T21:09:42.867648Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./git/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling up the complexity from a simple linear regression, now imagine that we have a series of inputs (independent variables) where each $x_i$ is not a single number but a vector of length $k$:\n",
    "\n",
    "$$x_i,...,x_k$$\n",
    "\n",
    "The multiple regression linear model assumes that:\n",
    "\n",
    "$$y_i = \\alpha + \\beta_1x_i1 + ... + \\beta_k x_(ik) + \\varepsilon_i$$\n",
    "\n",
    "In multiple regression the vector of paramters is usually called $\\beta$. We'll want thi to include the constant term as well, which we can achieve by adding a column of 1s to our data:\n",
    "\n",
    "`beta = [alpha,beta_1,...,beta_k]`\n",
    "\n",
    "and\n",
    "\n",
    "`x_i = [1,x_i1,...,x_ik]`\n",
    "\n",
    "Then the model is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.885169Z",
     "start_time": "2020-03-21T21:09:42.870980Z"
    }
   },
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import dot, Vector\n",
    "\n",
    "def predict(x: Vector, beta: Vector) -> float:\n",
    "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
    "    return dot(x,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input vector will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.893049Z",
     "start_time": "2020-03-21T21:09:42.887274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 49, 4, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, # constant term\n",
    " 49, # number of friends\n",
    " 4, # work hours per day\n",
    " 0] # doesn't have PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further assumptions in the least squares model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra assumptions make the model work:\n",
    "\n",
    "- the columns of `x_i` (the input variables) are linearly independent i.e. there is no way to write any one as a weighted sum of some of the others. If this assumption fails, you can't estimate beta.\n",
    "- all of the columns of `x_i` are uncorrelated with the errors $\\varepsilon$. If this isn't true, our $\\beta$ estimates will be systematically wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.901032Z",
     "start_time": "2020-03-21T21:09:42.895075Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def error(x: Vector, \n",
    "          y: float,\n",
    "          beta:Vector) -> float:\n",
    "    return predict(x,beta) - y\n",
    "\n",
    "def squared_error(x:Vector,\n",
    "                  y:float,\n",
    "                  beta:Vector) -> float:\n",
    "    return error(x,y,beta) ** 2\n",
    "\n",
    "x = [1,2,3]\n",
    "y = 30\n",
    "beta = [4,4,4]\n",
    "\n",
    "assert error(x,y,beta) == -6\n",
    "assert squared_error(x,y,beta) == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.909001Z",
     "start_time": "2020-03-21T21:09:42.902290Z"
    }
   },
   "outputs": [],
   "source": [
    "def sqerror_gradient(x:Vector,\n",
    "                     y:float,\n",
    "                     beta:Vector) -> Vector:\n",
    "    err = error(x,y,beta)\n",
    "    return [2*err*x_i for x_i in x]\n",
    "\n",
    "assert sqerror_gradient(x,y,beta) == [-12,-24,-36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:42.932906Z",
     "start_time": "2020-03-21T21:09:42.909959Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "from scratch.linear_algebra import vector_mean\n",
    "from scratch.gradient_descent import gradient_step\n",
    "\n",
    "def least_squares_fit(xs:List[Vector],\n",
    "                      ys:List[float],\n",
    "                      learning_rate:float = 0.001,\n",
    "                      num_steps: int = 1000,\n",
    "                      batch_size: int = 1) -> Vector:\n",
    "    \"\"\"\n",
    "    Find the beta that minimises the sum of squared errors\n",
    "    assuming the model y = dot(x,beta)\n",
    "    \"\"\"\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "    \n",
    "    for _ in tqdm.trange(num_steps,desc='least squares fit'):\n",
    "        for start in range(0,len(xs),batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "            \n",
    "            gradient = vector_mean([sqerror_gradient(x,y,guess) \n",
    "                                    for x,y in zip(batch_xs,batch_ys)])\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:09:45.415936Z",
     "start_time": "2020-03-21T21:09:42.936407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 2059.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scratch.statistics import daily_minutes_good\n",
    "from scratch.gradient_descent import gradient_step\n",
    "\n",
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "\n",
    "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "\n",
    "beta = least_squares_fit(inputs,\n",
    "                         daily_minutes_good,\n",
    "                         learning_rate,\n",
    "                         5000,\n",
    "                         25)\n",
    "print(beta)\n",
    "\n",
    "# assert 30.50 < beta[0] < 30.70  # constant\n",
    "# assert  0.96 < beta[1] <  1.00  # num friends\n",
    "# assert -1.89 < beta[2] < -1.85  # work hours per day\n",
    "# assert  0.91 < beta[3] <  0.94  # has PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients of the model (the beta values) can be thought of being estimates of the impact of each factor (each feature, each variable) on the output variable **all else being equal**.\n",
    "\n",
    "All else being equal, each additional friend corresponds to an extra minute spent on the site each day. All else being equal, each additional hour in a user's workday corresponds to about two fewer minutes spent on the site each day. All else being equal, having a PhD is associated with spending an extra minute on the site each day.\n",
    "\n",
    "What this **doesn't** tell you anything about is the *interaction* between the variables. The hours someone works may influence people with more friends differently than people with fewer friends. Multiple regressions do not capture this. So how do you handle that?\n",
    "\n",
    "One way is to define a new variable that is the product of friends and work hours. This allows the work hours coefficient to increase or decrease as the number of friends increases.\n",
    "\n",
    "Alternatively, it could be that the more friends you have the more time you spend on the site *up to a certain point* at which further friends causes you to spend less time on the site. We could try to capture this by introducing another variable that is the  *square* of the number of friends.\n",
    "\n",
    "Once we start adding variables, we need to be very careful about whether their coefficients actually matter or mean anything. You have carte blanche to define any variables and as many variables as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we look to the r-squared value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:10:26.778351Z",
     "start_time": "2020-03-21T21:10:26.771939Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.422023502508536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scratch.simple_linear_regression import total_sum_of_squares\n",
    "\n",
    "def multiple_r_squared(xs: List[Vector],\n",
    "                       ys: Vector,\n",
    "                       beta: Vector) -> float:\n",
    "    sum_of_squared_errors = sum(error(x,y,beta)**2 \n",
    "                                for x,y in zip(xs,ys))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)\n",
    "\n",
    "multiple_r_squared(inputs,daily_minutes_good,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:10:41.333397Z",
     "start_time": "2020-03-21T21:10:41.266678Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
